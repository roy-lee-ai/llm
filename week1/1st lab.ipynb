{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6613bad",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24eaf0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                                 # Standard library to access system environment variables\n",
    "from dotenv import load_dotenv            # Loads environment variables from a .env file\n",
    "from scraper import fetch_website_contents # Custom module to scrape and extract website content\n",
    "from IPython.display import Markdown, display # Utilities for rich text rendering in Jupyter Notebooks\n",
    "from openai import OpenAI                 # Official OpenAI client for API interactions\n",
    "\n",
    "# Initialize environment variables and the OpenAI client before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cdc465",
   "metadata": {},
   "source": [
    "### Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b33c17e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)                 # Load .env file and overwrite existing environment variables\n",
    "api_key = os.getenv('OPENAI_API_KEY')      # Retrieve the OpenAI API key from environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae44e53",
   "metadata": {},
   "source": [
    "### Types of prompts\n",
    "\n",
    "Models like GPT have been trained to receive instructions in a particular way.\n",
    "\n",
    "They expect to receive:\n",
    "\n",
    "**A system prompt** that tells them what task they are performing and what tone they should use\n",
    "\n",
    "**A user prompt** -- the conversation starter that they should reply to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ad95a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a detail oriented assistant that analyzes the contents of a website,\n",
    "and provides a summary, ignoring text that might be navigation related.\n",
    "Respond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fd7f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_prefix = \"\"\"\n",
    "Here are the contents of a website.\n",
    "Provide a short summary of this website.\n",
    "If it includes news or announcements, then summarize these too.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2d735e",
   "metadata": {},
   "source": [
    "## And now let's build useful messages for GPT-4.1-mini, using a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d72ee62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_prefix + website}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e55b22be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '\\nYou are a kind assistant that analyzes the contents of a website,\\nand provides a kind and detailed summary, ignoring text that might be navigation related.\\nRespond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\\n'},\n",
       " {'role': 'user',\n",
       "  'content': \"\\nHere are the contents of a website.\\nProvide a short summary of this website.\\nIf it includes news or announcements, then summarize these too.\\nRoy Lee\\n\\nRoy Lee\\nRoy Lee's playground\\nHOME\\nABOUT\\nCATEGORIES\\nTAGS\\nARCHIVES\\nHome\\nRoy Lee\\nCancel\\nIntro to Quantization\\nComplete Guide to LLM Quantization & Compression: Summary 1. Overview & Key Statistics Objective: Enable large-scale models (70B+) to run on standard gaming laptops or small GPU environ...\\nDec 30, 2025\\nLLM\\nIntro to Multiprocessing\\n1. Overview of Multiprocessing Key Concepts Definition: A technique that replicates processes to run independently within separate memory spaces. Structure: Each process independently maintai...\\nDec 30, 2025\\nLLMOps\\nIntroduction to Asynchronous Programming\\nIntroduction to Asyncio The Paradigm Shift in Concurrent Programming The Paradigm Shift in Concurrent Programming Traditionally, concurrent programming has been achieved by utilizing multiple thr...\\nDec 22, 2025\\nLLMOps\\nHow to Choose the Right LLM\\nHow to Choose the Right LLM Choosing an LLM isn’t about finding the “best” model, but the “right” one for your specific task. 1. Step One: Drill into Business Requirements Before looking at mode...\\nDec 20, 2025\\nLLMOps\\nMy First ML Project\\nThe First Machine Learning Project for everyone Background This project is based on the first ML algorithm introduced in my favorite Korean machine learning book (ISBN: 9791158393229). The algori...\\nSep 23, 2025\\nMachine Learning\\nRecently Updated\\nIntro to Quantization\\nIntroduction to Asynchronous Programming\\nIntro to Multiprocessing\\nHow to Choose the Right LLM\\nMy First ML Project\\nTrending Tags\\nllmops\\npython\\nasyncio\\nllm\\nmachine learning\\nmultiprocessing\\nquantizaiton\\n©\\n2025\\nRoy Lee\\n.\\nSome rights reserved.\\nUsing the\\nChirpy\\ntheme for\\nJekyll\\n.\\nTrending Tags\\nllmops\\npython\\nasyncio\\nllm\\nmachine learning\\nmultiprocessing\\nquantizaiton\\nA new version of content is available.\\nUpdate\"}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this out, and then try for a few more websites\n",
    "\n",
    "messages_for(roy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f09b0ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API. You will get very familiar with this!\n",
    "\n",
    "def summarize(url):\n",
    "    website = fetch_website_contents(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4.1-mini\",\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed2c93bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Website Summary: Roy Lee\\'s Playground\\n\\nThis website serves as a personal blog and knowledge hub curated by Roy Lee, primarily focused on advanced topics related to machine learning (ML), large language models (LLMs), and programming concepts.\\n\\n## Main Content\\n\\n- **Tutorials and Guides:** The site hosts detailed articles like \"Complete Guide to LLM Quantization & Compression,\" \"Intro to Multiprocessing,\" \"Introduction to Asynchronous Programming,\" and advice on \"How to Choose the Right LLM.\"\\n- **Educational Projects:** There is content aimed at beginners, such as \"My First ML Project,\" which guides readers through their initial machine learning algorithm based on a noted Korean textbook.\\n- **Focus Areas:** Key themes include LLM operations (LLMOps), asynchronous programming with asyncio, multiprocessing, quantization, and general machine learning principles.\\n\\n## News and Announcements\\n\\n- The site notes when content has been recently updated, highlighting articles such as \"Intro to Quantization,\" \"Introduction to Asynchronous Programming,\" and \"Intro to Multiprocessing.\"\\n- A message at the bottom occasionally alerts visitors to new versions of content being available, encouraging updates to the latest material.\\n\\n## Additional Details\\n\\n- The site uses the Chirpy theme for Jekyll.\\n- Articles are tagged for easy browsing with trending tags like `llmops`, `python`, `asyncio`, `llm`, `machine learning`, `multiprocessing`, and `quantization`.\\n- Content is aimed at enabling practical ML and LLM deployment on accessible hardware, such as gaming laptops or small GPUs.\\n\\nIn summary, Roy Lee\\'s website is a resource-rich platform that provides educational and practical insights into modern machine learning techniques and operations, with frequent updates and beginner-friendly projects.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://www.roy-lee-ai.com\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
